<story-context id=".bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>3</epicId>
    <storyId>1</storyId>
    <title>Quiz Generation Backend</title>
    <status>drafted</status>
    <generatedAt>2025-12-09</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/3-1-quiz-generation-backend.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>a developer</asA>
    <iWant>to create a backend service that generates a quiz based on the original content</iWant>
    <soThat>users can test their knowledge</soThat>
    <tasks>
- [ ] **Task 1: Implement Quiz Generation Service (AC: 1, 2, 3, 4)**
  - [ ] Subtask 1.1: Create a `QuizService` in `backend/app/core/`.
  - [ ] Subtask 1.2: Implement a method that takes content and difficulty level as input and returns quiz questions.
  - [ ] Subtask 1.3: Integrate the `LLMClient` to communicate with the LLM provider for question generation.
  - [ ] Subtask 1.4: Implement error handling for LLM API calls.
- [ ] **Task 2: Create API Endpoint (AC: 1, 2, 3, 4)**
  - [ ] Subtask 2.1: Create a `POST /api/quiz` endpoint in `backend/app/api/`.
  - [ ] Subtask 2.2: The endpoint should accept `content_id` and `difficulty` in the request body.
  - [ ] Subtask 2.3: The endpoint should call the `QuizService` and return the quiz questions.
- [ ] **Task 3: Asynchronous Task (AC: 1, 2, 3, 4)**
  - [ ] Subtask 3.1: Create a Celery task for the quiz generation process.
  - [ ] Subtask 3.2: The API endpoint should initiate the Celery task and return a `202 Accepted` response.
- [ ] **Task 4: Write Backend Tests (AC: 1, 2, 3, 4)**
  - [ ] Subtask 4.1: Write unit tests for the `QuizService`.
  - [ ] Subtask 4.2: Write integration tests for the `POST /api/quiz` endpoint.
    </tasks>
  </story>

  <acceptanceCriteria>
1.  Given content is available on the backend, when the quiz generation service is called, then a set of questions and answers is returned in a structured format (e.g., JSON).
2.  Given a difficulty level is provided, when the service is called, then the quiz questions match the requested difficulty.
3.  (NFR2) Given the LLM API call fails, when I call the service, then a proper error is returned and the system handles it gracefully.
4.  (NFR6) The service seamlessly integrates with the chosen LLM provider.
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-3.md</path>
        <title>Epic Technical Specification: Adaptive Quizzing</title>
        <section>Detailed Design</section>
        <snippet>| Service/Module | Responsibility | Inputs | Outputs | Owner |
| --- | --- | --- | --- | --- |
| `QuizService` | Orchestrates quiz generation, assessment, and adaptation logic. | Content, difficulty, user answers | Quiz questions, feedback, adaptive quiz parameters | Backend Team |
| `LLMClient` | Communicates with the external LLM provider. | Prompt, content | LLM response | Backend Team |</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>API Contracts</section>
        <snippet>All API responses will be in JSON format. Use standard HTTP status codes (e.g., 200 OK, 201 Created, 400 Bad Request, 500 Internal Server Error).</snippet>
      </doc>
      <doc>
        <path>docs/epics-QuizZum-2025-12-05.md</path>
        <title>QuizZum - Epic Breakdown</title>
        <section>Story 3.1: (MVP) Quiz Generation Backend</section>
        <snippet>User Story: As a developer, I want to create a backend service that generates a quiz based on the original content, so that users can test their knowledge.</snippet>
      </doc>
    </docs>
    <code>
      <file>
        <path>backend/app/core/quiz_service.py</path>
        <action>Create</action>
        <reason>The service for handling quiz generation logic.</reason>
      </file>
      <file>
        <path>backend/app/api/quiz.py</path>
        <action>Create</action>
        <reason>The endpoint for handling quiz generation requests.</reason>
      </file>
      <file>
        <path>backend/app/tasks/quiz_tasks.py</path>
        <action>Create</action>
        <reason>The Celery task for asynchronous quiz generation.</reason>
      </file>
    </code>
    <dependencies>
      <ecosystem>
        <name>Node.js (frontend)</name>
        <package>
          <name>react</name>
          <version>latest</version>
        </package>
        <package>
          <name>next</name>
          <version>latest</version>
        </package>
        <package>
          <name>@chakra-ui/react</name>
          <version>latest</version>
        </package>
        <package>
          <name>@emotion/react</name>
          <version>latest</version>
        </package>
        <package>
          <name>@emotion/styled</name>
          <version>latest</version>
        </package>
        <package>
          <name>framer-motion</name>
          <version>latest</version>
        </package>
      </ecosystem>
      <ecosystem>
        <name>Python (backend)</name>
        <package>
          <name>fastapi</name>
          <version>latest</version>
        </package>
        <package>
          <name>uvicorn</name>
          <version>latest</version>
        </package>
        <package>
          <name>python-multipart</name>
          <version>latest</version>
        </package>
        <package>
          <name>celery</name>
          <version>latest</version>
        </package>
        <package>
          <name>redis</name>
          <version>latest</version>
        </package>
      </ecosystem>
    </dependencies>
  </artifacts>

  <constraints>
      <constraint>The backend is a FastAPI application.</constraint>
      <constraint>Long-running tasks like quiz generation must be handled asynchronously using Celery.</constraint>
      <constraint>The `LLMClient` will be used for all communication with the LLM provider for question generation.</constraint>
      <constraint>All API responses must be in JSON format and use standard HTTP status codes.</constraint>
    </constraints>
  <interfaces>
      <interface>
        <name>Quiz Generation API</name>
        <kind>REST endpoint</kind>
        <signature>POST /api/quiz</signature>
        <path>backend/app/api/quiz.py</path>
      </interface>
    </interfaces>
  <tests>
      <standards>
        A layered testing approach will be adopted: Unit, Integration, E2E. Backend integration tests for API endpoints.
      </standards>
      <locations>
        Tests should be co-located with the source code. For example, `backend/app/tests/test_quiz.py`.
      </locations>
      <ideas>
        - Write unit tests for the `QuizService` to verify question generation logic for different difficulty levels.
        - Write integration tests for the `POST /api/quiz` endpoint, mocking the LLM client.
        - Write tests to ensure graceful error handling when the LLM API fails.
      </ideas>
    </tests>
</story-context>
